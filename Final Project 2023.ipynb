{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fc05751",
   "metadata": {},
   "source": [
    "# Final Project 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b19a78",
   "metadata": {},
   "source": [
    "description to be added"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99335445",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e3f12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All import statements needed for the project\n",
    "\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import geoalchemy2 as gdb\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import shapely\n",
    "import sqlalchemy as db\n",
    "\n",
    "from sqlalchemy.orm import declarative_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d04ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Any constants might needed\n",
    "\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"IRRl7waby6A5Hecvpg5A8mGG0\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"FINAL_PROJECT_4501_2023\"\n",
    "DB_USER = \"finalproject\"\n",
    "DB_URL = f\"postgresql://luyueying:yvonne0807@localhost/finalproject\"   \n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e20fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb64fc7",
   "metadata": {},
   "source": [
    "## Part 1 : Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2f2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_nyc_csv_data(data_url, access_token, start_dt, end_dt, storage_year=None, filename='NYC_311_Service_Requests', overwrite=False):\n",
    "    \"\"\"\n",
    "    Fetches NYC open data in CSV format for a given period.\n",
    "\n",
    "    Args:\n",
    "        data_url (str): Base URL for the data to be downloaded.\n",
    "        access_token (str): Token for API access.\n",
    "        start_dt (str): Start date for data retrieval.\n",
    "        end_dt (str): End date for data retrieval.\n",
    "        storage_year (int): Year for naming the CSV file. Defaults to None.\n",
    "        filename (str): Filename to be stored. Defaults to be 'NYC_311_Service_Requests'.\n",
    "        overwrite (bool, optional): Overwrites existing file if True. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set data storage directory \n",
    "    DATA_FOLDER = 'data'\n",
    "    os.makedirs(DATA_FOLDER, exist_ok=True)\n",
    "\n",
    "    # Initialize variables\n",
    "    records_per_request = 50000000\n",
    "    next_record = 0\n",
    "    data_collected = False\n",
    "\n",
    "    # Set CSV file name and path\n",
    "    csv_filename = f\"{filename}_{storage_year}.csv\"\n",
    "    csv_file_path = os.path.join(DATA_FOLDER, csv_filename)\n",
    "\n",
    "    if not overwrite and os.path.exists(csv_file_path):\n",
    "        print(\"File already exists. Set 'overwrite=True' to overwrite.\")\n",
    "        return\n",
    "\n",
    "    # Download data\n",
    "    while not data_collected:\n",
    "        # Constructing the API query with pagination\n",
    "        query = f\"?$$app_token={access_token}&$where=created_date between '{start_dt}' and '{end_dt}'&$limit={records_per_request}&$offset={next_record}\"\n",
    "        complete_data_url = f\"{data_url}{query}\"\n",
    "\n",
    "        response = requests.get(complete_data_url)\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Failed to download data. HTTP Status: {response.status_code}\")\n",
    "            break\n",
    "\n",
    "        # Write data to CSV file\n",
    "        mode = 'wb' if next_record == 0 else 'ab'\n",
    "        with open(csv_file_path, mode) as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "        next_record += records_per_request\n",
    "        data_collected = len(response.content) < records_per_request\n",
    "\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
